---
title: "PresentationNotes"
author: "Anna Schmoker"
date: "5/1/2018"
output: html_document
---
Make sure you have downloaded the **SampleData.csv** file from the homepage <https://aschmoke.github.io/Bio381_2018/>.

We will be using the following R packages:   
`plyr`
`ggplot2`
`ggrepel`
`patchwork`
`reshape2`

###Your .csv file
- convert "#" to "+" using a text editor (e.g. BBedit)
- remove spaces from column headers

```{r}
library(plyr)
library(ggplot2)
library(patchwork)
library(ggrepel)
library(reshape2)

d <- read.table(file="SampleData.csv",header=TRUE,sep=",")

head(d)
tail(d)

# Get some basic stats on the data

table(d$SampleID)
length(unique(d$GeneSymbol))
```
###What we need to do
1. Filters: high S:N, 3 or more peptides, remove proteins present in the control
2. Normalize H:L ratios to POI, get mean H:L and SD
3. Get a p-value for each protein (sig. increased/decreased binding)
4. Summarize


Take the heavy-to-light ratio out of Log2 space
```{r}
d$Ratio <- with(d, 2^Log2Ratio)
head(d)
```

### Subsetting all peptides that meet certain criteria
Require a signal-to-noise ratio > 20

```{r}
# We need a unique row!
d$Row <- with(d, 1:nrow(d))

# "create a subset of d, excluding any rows with a unique "Row" designation that has a "SumSN" value less than 20
dSN <- subset(d,!Row %in% Row[SumSN < 20])

table(dSN$SampleID)
length(unique(dSN$GeneSymbol))
```

###Summarize peptide information for each protein
Create a new dataset and summarize using `ddply()` with the `plyr` package
```{r}
# split the data frame
# apply a function
# combine results in a new data frame
dMean <- ddply(dSN,
               .(Reference,SampleID,GeneSymbol), # variables to split data frame by ("." to indicate variables without quoting)
               summarize, # summarize the following for each variable group
               Count=length(Reference),
               MeanFC=mean(Ratio),
               StDev=sd(Ratio))

head(dMean)
length(unique(dMean$GeneSymbol))

dFilt <- subset(dMean,!Reference %in% Reference[Count<3])
length(unique(dFilt$GeneSymbol))
```

###Remove proteins in control
Filter out all proteins in the control, unless "Count" is 5X higher in the experimental group.
```{r}
# Reshape into 'wide' format for easier manipulation
# Get Counts for each sample ID associated with a given Reference
dFiltW<-dcast(dFilt, Reference ~ SampleID, value.var = "Count")
head(dFiltW)
# Extract rows that have both A and B in Sample column using complete.cases
dFiltAB<-dFiltW[which(complete.cases(dFiltW)),]

# Create column that divides Sample B by A
dFiltAB$div<-dFiltAB$B/dFiltAB$A

# Subset only those where B is at least 5 times greater than A
dFiltLB<-subset(dFiltAB, dFiltAB$div>=5)

# Get names of those with either A or B
dFiltAorB<-dFiltW[which(!complete.cases(dFiltW)),]

# Subset only B samples
dFiltBs<-subset(dFiltAorB, dFiltAorB$B != "NA")

# Create a data frame that have References with either only B or where B > 5x A
namesToSubset<-data.frame(Names=c(as.character(dFiltLB$Reference), as.character(dFiltBs$Reference)))

# dFilt$Reference<-as.character(dFilt$Reference)
# head(dFilt)
# Subset original data to only include References that have B samples
dFiltBs<-subset(dFilt, dFilt$Sample=="B")
dFiltNew<-subset(dFiltBs, dFiltBs$Reference %in% namesToSubset$Names)

head(dFiltNew)
```

With an average Ratio for each protein, we can normalize to a loading control
```{r}
norm <- dFiltNew$MeanFC[dFiltNew$GeneSymbol=="Prkaca"]
norm

dFiltNew$FCnorm <- with(dFiltNew, MeanFC/norm)
```

Get p-value for each protein
```{r}
mNorm <- dFiltNew[dFiltNew$GeneSymbol=="Prkaca","FCnorm"]

sNorm <- dFiltNew[dFiltNew$GeneSymbol=="Prkaca","StDev"]

nNorm <- dFiltNew[dFiltNew$GeneSymbol=="Prkaca","Count"]

dFiltNew$pVal <- with(dFiltNew,
                   2*pt(
                     -abs(
                       ((FCnorm - mNorm)/
                          sqrt((((Count-1)*StDev^2 +
                                   (nNorm-1)*sNorm^2)/
                            (Count+nNorm-2))*(1/Count+1/nNorm)))),
                     (Count + nNorm - 2)),lower=FALSE)
# pt() gives the distribution function of the student t dist. To get the p-value, we need to multiply the pt() output by two. Futher, if the t value is positive, we need to use 1-t as input. We can get around this by taking the -abs(t).

# Adjust p-value for multiple calculations
dFiltNew$FDR <- p.adjust(dFiltNew$pVal,method="BH")

dFiltNew$Log2FCnorm <- with(dFiltNew, log(FCnorm,2))

dFiltNew$LogFDR <- with(dFiltNew, -log(FDR,10))

```

```{r}
dFiltNew$threshold <- as.factor(abs(dFiltNew$Log2FCnorm) > 2 &
                                  dFiltNew$FDR < 0.05)

p1 <- ggplot(data=dFiltNew, aes(x=Log2FCnorm, y=LogFDR, color=threshold)) +
  geom_point(size=1.75) +
  scale_color_manual(values = c("darkgrey", "red")) +
  theme_bw() +
  theme(legend.position = "none") +
  geom_text_repel(data=subset(dFiltNew,FDR < 0.05 &
                                  abs(Log2FCnorm) > 2),
                    aes(label = GeneSymbol),
                    size = 2.5,
                    color="black",
                    box.padding = unit(0.35, "lines"),
                    point.padding = unit(0.3, "lines")) # repel overlapping text labels

# order rows by Log2-transformed mean fold change
dFiltNew <- dFiltNew[order(dFiltNew$Log2FCnorm),] 

# add rank order based on Log2Ratio
dFiltNew$Rank <- with(dFiltNew, 1:nrow(dFiltNew))


p2 <- ggplot(data=dFiltNew,mapping=aes(x=Rank,y=Log2FCnorm,color=threshold)) +
  geom_point(size=1.75) +
  scale_color_manual(values = c("darkgrey", "red")) +
  theme_bw() +
  theme(legend.position = "none") +
  geom_text_repel(data=subset(dFiltNew,FDR < 0.05 &
                                abs(Log2FCnorm) > 2),
                  aes(label = GeneSymbol),
                  size = 2.5,
                  color="black",
                  box.padding = unit(0.35, "lines"),
                  point.padding = unit(0.3, "lines"))

p3 <- ggplot(data=dFiltNew,mapping=aes(Log2FCnorm,fill=I("dodgerblue"), color=I("black"))) +
  geom_histogram() +
  theme_bw()

p3 + {
  p2 +
    p1 +
    plot_layout(nrow=1)
} +
  plot_layout(ncol=1)
```